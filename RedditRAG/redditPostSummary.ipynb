{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Introduction\n",
    "\n",
    "In this notebook, we'll walk through building a **Reddit Summarizer and Q&A Bot** using **Retrieval-Augmented Generation (RAG)**. This application demonstrates how to leverage the **Reddit API** to fetch and process Reddit posts and comments, summarize lengthy discussions.\n",
    "\n",
    "The setup combines several powerful tools and techniques:\n",
    "- **PRAW** to access Reddit data programmatically,\n",
    "- **LangChain** to handle prompt generation and retrieval workflows,\n",
    "- **FAISS** to efficiently store and retrieve relevant text chunks, and\n",
    "- **Llama 3.2** from **Ollama**, which powers the language model for natural language understanding and response generation.\n",
    "\n",
    "By the end of this tutorial, you’ll have a functional RAG-based application that summarizes and answers questions about Reddit discussions. This guide serves as a foundation for more advanced applications, like conducting subreddit-wide searches, analyzing trending topics, or building a comprehensive Reddit insights tool.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Prerequisites\n",
    "\n",
    "Before starting with the RAG solution for summarizing Reddit posts using PRAW, ensure you have the following set up:\n",
    "\n",
    "1. **Python 3.7+**: Make sure Python is installed. [Download it here](https://www.python.org/downloads/).\n",
    "\n",
    "2. **PRAW Library**: A Python library for accessing the Reddit API, used to fetch posts and comments.\n",
    "\n",
    "3. **Reddit API Credentials**: \n",
    "   - Go to [Reddit App Preferences](https://www.reddit.com/prefs/apps) and create a new application.\n",
    "   - Choose **\"Script\"** as the app type, set a name (e.g., \"Reddit Summarizer\"), and use `http://localhost:8000` as the redirect URI.\n",
    "   - This setup will provide your **client_id**, **client_secret**, and **user_agent**, which are needed to authenticate with the Reddit API.\n",
    "\n",
    "4. **Key Libraries**:\n",
    "   - **LangChain**: Manages prompt generation and helps structure the RAG workflow.\n",
    "   - **FAISS**: Efficiently stores and retrieves similar text chunks.\n",
    "   - **Hugging Face Transformers**: Provides pre-trained models for text embeddings.\n",
    "\n",
    "5. **Llama 3.2 via Ollama**:\n",
    "   - Set up **Ollama** to access **Llama 3.2** as the language model, which powers both the summarization and Q&A functionalities in the app. Visit the [Ollama website](https://ollama.com/) for setup instructions.\n",
    "\n",
    "With these prerequisites ready, you’re all set to build a robust RAG-powered Reddit Summarizer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install praw langchain faiss-cpu sentence-transformers streamlit python-dotenv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure Reddit API Credentials\n",
    "To securely access Reddit, store your credentials in a .env file in your project directory. This allows your code to load credentials without hardcoding them. Use the python-dotenv package to load these credentials:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import praw\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the variables\n",
    "client_id = os.getenv(\"client_id\")\n",
    "client_secret = os.getenv(\"client_secret\")\n",
    "user_agent = os.getenv(\"user_agent\")\n",
    "\n",
    "# Initialize PRAW with credentials\n",
    "reddit = praw.Reddit(\n",
    "    client_id=client_id,\n",
    "    client_secret=client_secret,\n",
    "    user_agent=user_agent\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With your environment set up and libraries installed, you’re ready to start fetching and processing Reddit data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch Data from Reddit\n",
    "Example 1: Fetching Posts from a Subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: [D] Simple Questions Thread\n",
      "Score: 4\n",
      "ID: 1giq4ia\n",
      "URL: https://www.reddit.com/r/MachineLearning/comments/1giq4ia/d_simple_questions_thread/\n",
      "\n",
      "Title: [D] Monthly Who's Hiring and Who wants to be Hired?\n",
      "Score: 30\n",
      "ID: 1ftdkmb\n",
      "URL: https://www.reddit.com/r/MachineLearning/comments/1ftdkmb/d_monthly_whos_hiring_and_who_wants_to_be_hired/\n",
      "\n",
      "Title: [R] Never Train from scratch\n",
      "Score: 63\n",
      "ID: 1gk7dny\n",
      "URL: https://www.reddit.com/r/MachineLearning/comments/1gk7dny/r_never_train_from_scratch/\n",
      "\n",
      "Title: [D] To what cross-entropy loss value can LLMs converge?\n",
      "Score: 25\n",
      "ID: 1gk92rs\n",
      "URL: https://www.reddit.com/r/MachineLearning/comments/1gk92rs/d_to_what_crossentropy_loss_value_can_llms/\n",
      "\n",
      "Title: [D] Autograd vs JAX? Both are google products aimed at gradient based methods. What’s the main difference? (GPU/TPU?)\n",
      "Score: 3\n",
      "ID: 1gkms4w\n",
      "URL: https://www.reddit.com/r/MachineLearning/comments/1gkms4w/d_autograd_vs_jax_both_are_google_products_aimed/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Choose a subreddit\n",
    "subreddit = reddit.subreddit(\"MachineLearning\")\n",
    "\n",
    "# Fetch the top 5 posts from 'Hot'\n",
    "for post in subreddit.hot(limit=5):\n",
    "    print(f\"Title: {post.title}\")\n",
    "    print(f\"Score: {post.score}\")\n",
    "    print(f\"ID: {post.id}\")\n",
    "    print(f\"URL: {post.url}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Fetching Comments from a Post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: [R] Never Train from scratch\n",
      "Content: https://arxiv.org/pdf/2310.02980 \n",
      "\n",
      "The authors show that when transformers are pre trained, they can match the performance with S4 on the Long range Arena benchmark. \n",
      "Comment by like_a_tensor: I don't get why this paper was accepted as an Oral. It seems obvious, and everyone already knew that pre-training improves performance. I thought the interesting question was always whether long-range performance could be achieved via architecture alone without any pre-training task.\n",
      "Comment by Sad-Razzmatazz-5188: TL;DR self-supervised pre-training on the downstream task is always better than random initialization, and structured initialization is a bit better even for pretraining; fancy models are not much better than transformers when all's pretrained.\n",
      "\n",
      "\n",
      "Take home message: we're still messing around because backpropagation almost always converges to a local minimum, but we ignore most of the loss landscape and how privileged regions bring to privileged local minima\n",
      "Comment by EducationalSchool359: Probably the most unfortunately written abstract I've seen in a while. They should really make it clear that they pretrain both the transformer and the SSM, otherwise my immediate reaction is, \"yeah obviously?\"\n",
      "Comment by Dangerous-Goat-3500: Can anyone link a good paper that explains what self-supervised pre-training is? \n",
      "\n",
      "This seems cool and interesting, but it, and even its references regarding self-supervised pretraining, don't really explain what it is.\n"
     ]
    }
   ],
   "source": [
    "# Get a specific post by ID\n",
    "post = reddit.submission(id=\"1gk7dny\")\n",
    "\n",
    "# Print post details\n",
    "print(f\"Title: {post.title}\")\n",
    "print(f\"Content: {post.selftext}\")\n",
    "\n",
    "# Fetch top-level comments\n",
    "for comment in post.comments[:5]:  # limit comments if needed\n",
    "    print(f\"Comment by {comment.author}: {comment.body}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3: Searching Subreddit Posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Should r/MachineLearning join the reddit blackout to protest changes to their API?\n",
      "Score: 2620\n",
      "ID: 14265di\n",
      "URL: https://www.reddit.com/r/MachineLearning/comments/14265di/should_rmachinelearning_join_the_reddit_blackout/\n",
      "\n",
      "Title: [D] I feel like ever since LLM APIs have become a thing the quality of discussion regarding ML and ML products has gone down drastically.\n",
      "Score: 409\n",
      "ID: 1fl5be0\n",
      "URL: https://www.reddit.com/r/MachineLearning/comments/1fl5be0/d_i_feel_like_ever_since_llm_apis_have_become_a/\n",
      "\n",
      "Title: [D] New Reddit API terms effectively bans all use for training AI models, including research use.\n",
      "Score: 595\n",
      "ID: 12r7qi7\n",
      "URL: https://www.reddit.com/r/MachineLearning/comments/12r7qi7/d_new_reddit_api_terms_effectively_bans_all_use/\n",
      "\n",
      "Title: [D] OpenAI introduces ChatGPT and Whisper APIs (ChatGPT API is 1/10th the cost of GPT-3 API)\n",
      "Score: 576\n",
      "ID: 11fbccz\n",
      "URL: https://www.reddit.com/r/MachineLearning/comments/11fbccz/d_openai_introduces_chatgpt_and_whisper_apis/\n",
      "\n",
      "Title: [News] New Google tech - Geospatial API uses computer vision and machine learning to turn 15 years of street view imagery into a 3d canvas for augmented reality developers\n",
      "Score: 1398\n",
      "ID: uqk878\n",
      "URL: https://v.redd.it/3yjjeuprnqz81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Search for posts containing specific keywords\n",
    "for post in subreddit.search(\"API\", limit=5):\n",
    "    print(f\"Title: {post.title}\")\n",
    "    print(f\"Score: {post.score}\")\n",
    "    print(f\"ID: {post.id}\")\n",
    "    print(f\"URL: {post.url}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval Augmented Generation on Reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "import faiss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunk Text for Vector Storage\n",
    "We'll use PRAW to get the main content and all comments from a Reddit post. The goal is to create a rich text dataset that combines the post and comment threads for more context in summaries and answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_reddit_post(url):\n",
    "    \"\"\"Fetch and process Reddit post and comments, returning chunked Document objects.\"\"\"\n",
    "    submission = reddit.submission(url=url)\n",
    "    submission.comments.replace_more(limit=None)\n",
    "    content = submission.selftext + \"\\n\" + \"\\n\".join([comment.body for comment in submission.comments.list()])\n",
    "\n",
    "    # Chunk content for FAISS storage using RecursiveCharacterTextSplitter\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=50)\n",
    "    chunks = splitter.split_text(content)\n",
    "\n",
    "    # Create Document objects for the chunks\n",
    "    documents = [Document(page_content=chunk) for chunk in chunks]\n",
    "\n",
    "    # Ingest into FAISS vector database\n",
    "    vector_db=ingest_into_vectordb(documents)\n",
    "\n",
    "    return vector_db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This `chunk_content` function splits text into chunks and creates Document objects, preparing them for vector storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l3/524d7s611rs3hl7hsd6rk25w0000gn/T/ipykernel_31154/2872171290.py:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=embedding_model)\n",
      "/Users/vikrambhat/Documents/GitHub/RAG-Implementation-with-ConversationUI/RAG Implementation Notebook/.venv/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/Users/vikrambhat/Documents/GitHub/RAG-Implementation-with-ConversationUI/RAG Implementation Notebook/.venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "embedding_model = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "embeddings = HuggingFaceEmbeddings(model_name=embedding_model)\n",
    "def ingest_into_vectordb(split_docs):\n",
    "    \"\"\"Store split documents in FAISS vector database and save locally.\"\"\"\n",
    "    db = FAISS.from_documents(split_docs, embeddings)\n",
    "    DB_FAISS_PATH = 'vectorstore/db_faiss'\n",
    "    db.save_local(DB_FAISS_PATH)\n",
    "    print(\"Documents are inserted into FAISS vectorstore\")\n",
    "    return db\n",
    "\n",
    "# Define PromptTemplate for summarization and Q&A\n",
    "prompt_template = PromptTemplate(input_variables=[\"text\"], template=\"{text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents are inserted into FAISS vectorstore\n"
     ]
    }
   ],
   "source": [
    "url=\"https://www.reddit.com/r/MachineLearning/comments/1gjoxpi/what_problems_do_large_language_models_llms/\"\n",
    "if url:\n",
    "    # Process Reddit post if URL is provided\n",
    "    vector_db = process_reddit_post(url)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Llama 3.2 for Summarization and Q&A\n",
    "After storing Reddit data in FAISS, we leverage Llama 3.2 to generate summaries and answer questions based on Reddit threads. Here's how it works in each mode:\n",
    "#### Summarization Mode\n",
    "We perform a similarity search in FAISS to retrieve the most relevant chunks from the Reddit post. A prompt like \"Summarize this content\" is passed to Llama 3.2, which generates a concise summary based on the retrieved data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(model=\"llama3.2\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Summarize this reddit content.\"\n",
    "relevant_docs = vector_db.similarity_search(query, k=5)\n",
    "context = \" \".join([doc.page_content for doc in relevant_docs])\n",
    "\n",
    "# Chain prompt with LLM using RunnableSequence\n",
    "summary = (prompt_template | llm).invoke(context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Here's a summary of the key points:\\n\\n* LLMs excel at Natural Language Generation tasks such as summarizing text, creating coherent and grammatically correct content.\\n* They can recognize when image recognition is requested and can initiate that process.\\n* However, LLMs are not capable of image recognition themselves.\\n* They primarily perform text generation, which is a part of structured prediction.\\n* Many professionals believe in continuous improvement, leading to skepticism about the need for proof.\\n\\nAdditionally, some key tasks mentioned include:\\n\\n* Summarization\\n* Coding\\n* Information Retrieval\\n* Spelling/grammar correction\\n* Needle-in-a-haystack search (finding relevant text in large corpora)\\n\\nLet me know if you'd like me to expand on any of these points!\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q&A Mode\n",
    "When users ask a question, FAISS finds the most relevant text chunks, which are then combined with a question-specific prompt. Llama 3.2 processes this input to provide an answer based on the context and user question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what exaCtly happened\"\n",
    "if question:\n",
    "            # Retrieve top chunks for Q&A\n",
    "            relevant_docs = vector_db.similarity_search(question, k=5)\n",
    "            context = \" \".join([doc.page_content for doc in relevant_docs])\n",
    "\n",
    "            # Prepare the input for the question prompt template\n",
    "            question_template = PromptTemplate(\n",
    "                input_variables=[\"text\", \"question\"],\n",
    "                template=\"Here are the comments on a reddit post\\n Answer the question based on context: {text}. Question: {question}\"\n",
    "            )\n",
    "            input_data = {\"text\": context, \"question\": question}  \n",
    "\n",
    "            answer = (question_template | llm).invoke(input_data)\n",
    "            print(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "In this Notebook, we explored how to build a Reddit Summarizer and Q&A Bot using a Retrieval-Augmented Generation (RAG) approach. By leveraging PRAW for data access, LangChain for prompt management, FAISS for similarity search, and Llama 3.2 for language generation, we created a streamlined application that can summarize Reddit discussions and answer questions based on user input.\n",
    "This app demonstrates a practical RAG application on Reddit data, providing a sample solution for extracting insights from community discussions.\n",
    "#### Future Enhancements\n",
    "While this version focuses on individual Reddit posts, there are several ways to expand its capabilities:\n",
    "- Subreddit-Wide Searches: Extend the app to handle searches across an entire subreddit, summarizing trending discussions or providing answers based on broader topic data.\n",
    "- Trending Topic Analysis: Integrate analytics to detect trending topics or sentiments within specific subreddits, offering more comprehensive insights.\n",
    "- Advanced Question-Answering: Use additional LLMs or refine prompts to provide even more accurate and contextually rich answers.\n",
    "\n",
    "This project offers a foundation for further exploration and customization, opening the door to powerful applications in community-driven content analysis. With its adaptable setup, this RAG-based Reddit bot can be modified for a wide range of use cases across social media platforms."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
